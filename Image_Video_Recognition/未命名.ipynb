{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "# mnist数据源\n",
    "# Sequential类，可以封装各种神经网络层，包括Dense全连接层，Dropout层，Cov2D 卷积层等\n",
    "# keras后端TensorFlow\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation, Dropout\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# batch_size 太小会导致训练慢，过拟合等问题，太大会导致欠拟合。\n",
    "batch_size = 128\n",
    "# 0-9手写数字一个有10个类别\n",
    "num_classes = 10\n",
    "# epochs,12次完整迭代\n",
    "epochs = 12\n",
    "# 输入的图片是28*28像素的灰度图\n",
    "img_rows, img_cols = 28, 28\n",
    "# 训练集，测试集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    " \n",
    "# # keras输入数据有两种格式，一种是通道数放在前面，一种是通道数放在后面，\n",
    "if K.image_data_format() == 'channels_first':\n",
    " x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    " x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    " input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    # x_train(所有图像，1灰度通道，行，列)\n",
    " x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    " x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    " input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# # 二维数据变成一维数据\n",
    "# x_train = x_train.reshape(len(x_train), -1)\n",
    "# x_test = x_test.reshape(len(x_test), -1)\n",
    "\n",
    "\n",
    "# uint不能有负数，先转为float类型\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# 数据归一化,减去均值除以范围,最终是0-1的范围,\n",
    "# 所以最后的激活函数应该是sigmoid,如果是-1~1,那么激活函数应该是tanh\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# # 把类别0-9变成2进制，方便训练\n",
    "# y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Sequential类\n",
    "model = Sequential()\n",
    "\n",
    "# # # 建立模型\n",
    "# model.add(Dense(784, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "# model.add(Activation('relu'))\n",
    "# # 防止过拟合\n",
    "# model.add(Dropout(0.2)) \n",
    "\n",
    "# model.add(Dense(512, kernel_initializer='he_normal'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2)) \n",
    "\n",
    "\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# 加上一个2D卷积层， 32个输出（也就是卷积通道），激活函数选用relu，\n",
    "# 卷积核的窗口选用3*3像素窗口\n",
    "# 二维卷积层，即对图像的空域卷积。该层对二维输入进行滑动窗卷积，当使用该层作为第一层时，\n",
    "# 应提供input_shape参数。例如input_shape = (128,128,3)代表128*128的彩色RGB图像\n",
    "# filters即输出的维度，不用考虑输入维度，也就是卷积核的数目，也就是将平面的图像，拉伸成filters维的空间矩阵\n",
    "# \n",
    "model.add(Conv2D(32, (5,5), activation='relu', input_shape=input_shape, strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5,5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 配置模型使用交叉熵损失函数，最优化方法选用Adadelta\n",
    "# compile(self, optimizer, loss, metrics=None, sample_weight_mode=None)\n",
    "# optimizer：字符串（预定义优化器名）或优化器对象，参考优化器\n",
    "# loss：字符串（预定义损失函数名）或目标函数，参考损失函数\n",
    "# metrics：列表，包含评估模型在训练和测试时的网络性能的指标，典型用法是metrics=['accuracy']\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练过程\n",
    "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array\n",
    "# y：标签，numpy array\n",
    "# batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\n",
    "# epochs：整数，训练的轮数，每个epoch会把训练集轮一遍。\n",
    "# validation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    " verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
